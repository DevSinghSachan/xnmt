defaults:
  experiment:
    model_file: examples/output/<EXP>.mod
    hyp_file: examples/output/<EXP>.hyp
    out_file: examples/output/<EXP>.out
    err_file: examples/output/<EXP>.err
    run_for_epochs: 2
    eval_metrics: bleu
  train:
    default_layer_dim: 16
    dropout: 0.5
    batcher: !WordTrgSrcBatcher
      words_per_batch: 512
    dev_metrics: bleu
    training_corpus: !BilingualTrainingCorpus
      train_src: examples/data/train-char.ja
      train_trg: examples/data/train.en
      dev_src: examples/data/dev-char-head5.ja
      dev_trg: examples/data/dev-head5.en
    corpus_parser: !BilingualCorpusParser
      src_reader: !PlainTextReader {}
      trg_reader: !PlainTextReader {}
      max_src_len: 15
      max_trg_len: 15
    model: !DefaultTranslator
      calc_global_fertility: True
      src_embedder: !SimpleWordEmbedder
        emb_dim: 16
      encoder: !SegmentingSeqTransducer
        # Components
        embed_encoder: !LSTMSeqTransducer
          input_dim: 16
          hidden_dim: 16
          layers: 1
          bidirectional: True
        segment_composer: !SegmentComposer
          encoder: !LSTMSeqTransducer
            input_dim: 16
            hidden_dim: 16
            bidirectional: True
            layers: 1
          transformer: !TailSegmentTransformer {}
        final_transducer: !LSTMSeqTransducer
          input_dim: 16
          hidden_dim: 16
          bidirectional: True
          layers: 1
        # Options
        reinforce_scale: !GeometricSequence
          initial: 0.1
          ratio: 2
          warmup: 1
          min_value: 0.0
          max_value: 1.0
        confidence_penalty: !SegmentationConfidencePenalty
          strength: !ScalingParam
            initial: 0.1
            scaler: !GeometricSequence
              initial: 1
              ratio: 0.5
        length_prior: 3.3
        length_prior_alpha: !GeometricSequence
          initial: 1
          ratio: 0.5
        epsilon_greedy: !GeometricSequence
          initial: 0.3
          ratio: 0.5
        # Flags
        debug: True
        z_normalization: True
        learn_segmentation: True
        learn_delete: False
      attender: !MlpAttender
        state_dim: 16
        hidden_dim: 16
        input_dim: 16
      trg_embedder: !SimpleWordEmbedder
        emb_dim: 16
      decoder: !MlpSoftmaxDecoder
        layers: 1
        mlp_hidden_dim: 16
        bridge: !CopyBridge {}
  decode:
    src_file: examples/data/test-char-head5.ja
    report_path: examples/output/<EXP>.report
    report_type: html, file
  evaluate:
    ref_file: examples/data/test-head5.en

debug-segmenting:

