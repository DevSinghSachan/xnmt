standard:
  global:
    model_file: examples/output/<EXP>.mod
    out_file: examples/output/<EXP>.out
    err_file: examples/output/<EXP>.err
    dropout: 0.2
    default_layer_dim: 64
  model: !TransformerTranslator &main_model
    _xnmt_id: main_model
    src_reader: !PlainTextReader {}
    trg_reader: !PlainTextReader {}
    src_embedder: !SimpleWordEmbedder
      emb_dim: 64
      init: LeCunUniform
    encoder: !TransformerEncoder
      layers: 1
      input_dim: 64
    trg_embedder: !SimpleWordEmbedder
      emb_dim: 64
      init: LeCunUniform
    decoder: !TransformerDecoder
      layers: 1
      input_dim: 64
      label_smoothing: 0.0
    input_dim: 64
    inference: !SimpleInference {}
  train: !SimpleTrainingRegimen
    model: *main_model # TODO: remove this line
    run_for_epochs: 2
    restart_trainer: False
    lr_decay: 1.0
    src_file: examples/data/head-char.ja
    trg_file: examples/data/head.en
    dev_tasks:
      - !LossEvalTask
        model: *main_model # TODO: remove this line
        src_file: examples/data/dev-char-head5.ja
        ref_file: examples/data/dev-head5.en
  evaluate:
    - !AccuracyEvalTask
      model: *main_model # TODO: remove this line
      eval_metrics: bleu,wer
      src_file: examples/data/test-char-head5.ja
      ref_file: examples/data/test-head5.en
      hyp_file: examples/output/<EXP>.test_hyp
