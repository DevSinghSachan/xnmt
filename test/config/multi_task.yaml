# Simple example for multi-task training. Here, we have 2 identical tasks with
# some shared parameters.
multi_task_exp:
  global:
    model_file: examples/output/<EXP>.mod
    out_file: examples/output/<EXP>.out
    err_file: examples/output/<EXP>.err
    default_layer_dim: 64
  train: !SameBatchMultiTaskTrainingRegimen
    trainer: !AdamTrainer {}
    tasks:
    - !SimpleTrainingTask # first task is the main task: it will control early stopping, learning rate schedule, model checkpoints, ..
      name: first_task
      run_for_epochs: 6
      batcher: !SrcBatcher
        batch_size: 6 # batch size is twice as big as for task 2, which will give task 1 more impact during training
      src_file: examples/data/head.ja
      trg_file: examples/data/head.en
      model: !DefaultTranslator &first_task_model
        _xnmt_id: first_task_model
        src_reader: !PlainTextReader {}
        trg_reader: !PlainTextReader {}
        src_embedder: !SimpleWordEmbedder
          vocab_size: 500 # TODO: remove this line
          emb_dim: 64
        encoder: !BiLSTMSeqTransducer &first_task_encoder # the encoder shares parameters between tasks
          _xnmt_id: first_task_encoder
          layers: 1
        attender: !MlpAttender
          state_dim: 64
          hidden_dim: 64
          input_dim: 64
        trg_embedder: !SimpleWordEmbedder
          vocab_size: 500 # TODO: remove this line
          emb_dim: 64
        decoder: !MlpSoftmaxDecoder
          vocab_size: 500 # TODO: remove this line
          layers: 1
          lstm_dim: 64
          bridge: !CopyBridge {}
        inference: !SimpleInference {}
      dev_tasks:
        - !AccuracyEvalTask
          model: !Ref { name: first_task_model }
          src_file: &first_task_dev_src examples/data/head.ja  # value-sharing between train.training_corpus.dev_src and inference.src_file
          ref_file: &first_task_dev_trg examples/data/head.en  # value-sharing between train.training_corpus.dev_trg and evaluate.ref_file
          hyp_file: examples/output/<EXP>.first_dev_hyp
          eval_metrics: bleu # tasks can specify different dev_metrics
    - !SimpleTrainingTask
      name: second_task
      batcher: !SrcBatcher
        batch_size: 3
      src_file: examples/data/head.ja
      trg_file: examples/data/head.en
      model: !DefaultTranslator &second_task_model
        _xnmt_id: second_task_model
        src_reader: !PlainTextReader {}
        trg_reader: !PlainTextReader {}
        src_embedder: !SimpleWordEmbedder
          vocab_size: 500 # TODO: remove this line
          emb_dim: 64
        encoder: !Ref { name: first_task_encoder }
        attender: !MlpAttender
          state_dim: 64
          hidden_dim: 64
          input_dim: 64
        trg_embedder: !SimpleWordEmbedder
          vocab_size: 500 # TODO: remove this line
          emb_dim: 64
        decoder: !MlpSoftmaxDecoder
          vocab_size: 500 # TODO: remove this line
          layers: 1
          bridge: !CopyBridge {}
        inference: !SimpleInference {}
      dev_tasks:
        - !AccuracyEvalTask
          model: !Ref { name: second_task_model }
          src_file: examples/data/head.ja  # value-sharing between train.training_corpus.dev_src and inference.src_file
          ref_file: examples/data/head.en  # value-sharing between train.training_corpus.dev_trg and evaluate.ref_file
          hyp_file: examples/output/<EXP>.second_dev_hyp
          eval_metrics: gleu # tasks can specify different dev_metrics
  evaluate:
    - !AccuracyEvalTask &acc_task
      model: !Ref { name: first_task_model }
      eval_metrics: bleu,wer
      inference: !SimpleInference {}
      src_file: *first_task_dev_src
      ref_file: *first_task_dev_trg
      hyp_file: examples/output/<EXP>.test_hyp
