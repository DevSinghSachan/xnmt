# Simple example for multi-task training. Here, we have 2 identical tasks with
# some shared parameters and different batch sizes.
speech-multi:
  experiment:
    model_file: examples/output/<EXP>.mod
    hyp_file: examples/output/<EXP>.hyp
    out_file: examples/output/<EXP>.out
    err_file: examples/output/<EXP>.err
    eval_metrics: cer,wer
    save_num_checkpoints: 2
  train: !JointMultiTaskTrainingRegimen
    tasks:
    - !SimpleTrainingRegimen
      name: first_task
      run_for_epochs: 2
      src_format: contvec
      trainer: !AdamTrainer &task1_trainer 
        _xnmt_id: task1_trainer # Reference-sharing (both tasks' trainer must point to the same object)
      batcher: !SrcBatcher
        batch_size: 2
      glob:
        default_layer_dim: 32
        dropout: 0.4
      corpus_parser: !BilingualCorpusParser
        src_reader: !ContVecReader
          transpose: True
        trg_reader: !PlainTextReader {}
        training_corpus: !BilingualTrainingCorpus
          train_src: examples/data/synth.contvec.npz
          train_trg: examples/data/synth.char
          dev_src: examples/data/synth.contvec.npz
          dev_trg: examples/data/synth.char
      model: !DefaultTranslator
        src_embedder: !NoopEmbedder
          emb_dim: 240
        encoder: !PyramidalLSTMSeqTransducer &task1_encoder
          _xnmt_id: task1_encoder
          layers: 1
          downsampling_method: skip
          input_dim: 240
          hidden_dim: 64
        attender: !MlpAttender
          state_dim: 64
          hidden_dim: 64
          input_dim: 64
        trg_embedder: !SimpleWordEmbedder
          emb_dim: 64
        decoder: !MlpSoftmaxDecoder
          layers: 1
          mlp_hidden_dim: 64
          bridge: !CopyBridge {}
    - !SimpleTrainingRegimen
      name: second_task
      run_for_epochs: 5
      src_format: contvec
      trainer: *task1_trainer # point to task 1 trainer
      batcher: !SrcBatcher
        batch_size: 3
      glob:
        default_layer_dim: 32
        dropout: 0.4
      corpus_parser: !BilingualCorpusParser
        src_reader: !ContVecReader
          transpose: True
        trg_reader: !PlainTextReader {}
        training_corpus: !BilingualTrainingCorpus
          train_src: examples/data/synth.contvec.npz
          train_trg: examples/data/synth.char
          dev_src: examples/data/synth.contvec.npz
          dev_trg: examples/data/synth.char
      model: !DefaultTranslator
        src_embedder: !NoopEmbedder
          emb_dim: 240
        encoder: *task1_encoder
        attender: !MlpAttender
          state_dim: 64
          hidden_dim: 64
          input_dim: 64
        trg_embedder: !SimpleWordEmbedder
          emb_dim: 64
        decoder: !MlpSoftmaxDecoder
          layers: 1
          mlp_hidden_dim: 64
          bridge: !CopyBridge {}            
  decode: !SimpleInference
    src_file: examples/data/synth.contvec.npz
  evaluate:
    ref_file: examples/data/synth.char
