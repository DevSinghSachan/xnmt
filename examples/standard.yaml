standard:
  experiment:
    model_file: examples/output/<EXP>.mod
    hyp_file: examples/output/<EXP>.hyp
    out_file: examples/output/<EXP>.out
    err_file: examples/output/<EXP>.err
    cfg_file: examples/output/<EXP>.yaml
  model: !DefaultTranslator
    glob:
      dropout: 0.1
      default_layer_dim: 512
    src_reader: !PlainTextReader {}
    trg_reader: !PlainTextReader {}
    src_embedder: !SimpleWordEmbedder {}
    encoder: !BiLSTMSeqTransducer
      layers: 1
    attender: !MlpAttender {}
    trg_embedder: !SimpleWordEmbedder {}
    decoder: !MlpSoftmaxDecoder
      layers: 1
      mlp_hidden_dim: 512
      bridge: !CopyBridge {}
      label_smoothing: 0.1
    inference: !SimpleInference
      beam: 5
      len_norm_type: !PolynomialNormalization
        apply_during_search: true
  train: !SimpleTrainingRegimen
    run_for_epochs: 20
    batcher: !SrcBatcher
      batch_size: 32
    restart_trainer: True
    trainer: !AdamTrainer
      alpha: 0.0002
    lr_decay: 0.5
    src_file: examples/data/train.ja
    trg_file: examples/data/train.en
    dev_tasks:
      - !AccuracyEvalTask
        eval_metrics: bleu wer
        src_file: examples/data/dev.ja
        trg_file: examples/data/dev.en
      - !LossEvalTask
        src_file: examples/data/dev.ja
        trg_file: examples/data/dev.en
  evaluate:
    - !AccuracyEvalTask
      eval_metrics: bleu wer
      src_file: examples/data/test.ja
      trg_file: examples/data/test.en
